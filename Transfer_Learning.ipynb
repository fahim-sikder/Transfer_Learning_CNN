{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Transfer_Learning.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "metadata": {
        "id": "Tq7LZOQ7-4KT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Transfer Learning using CIFAR 10 dataset with Resnet 18 Weights using PyTorch"
      ]
    },
    {
      "metadata": {
        "id": "n1GRQadJn05k",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.autograd import Variable\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nbCwSsl1oczX",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# transform the dataset for ImageNet"
      ]
    },
    {
      "metadata": {
        "id": "qk4vsTCioVoR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "batch_size = 50\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.RandomHorizontalFlip(),\n",
        "    transforms.RandomVerticalFlip(),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])\n",
        "\n",
        "\n",
        "valid_transform = transforms.Compose([\n",
        "    transforms.Resize(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "KBj-9Vo9of-W",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "78c9dd71-72d3-4448-c0d8-a4d6a856a90c"
      },
      "cell_type": "code",
      "source": [
        "train_data = datasets.CIFAR10('./data',\n",
        "                              train = True,\n",
        "                             download = True,\n",
        "                              transform = train_transform\n",
        "                             )"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "kEzx-uOOqOpd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "be43c042-ea91-40d4-f817-1c6d2b5a7046"
      },
      "cell_type": "code",
      "source": [
        "valid_data = datasets.CIFAR10('./data',\n",
        "                              train = False,\n",
        "                             download = True,\n",
        "                              transform = valid_transform\n",
        "                             )"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "WBY7oINQsoeF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Data Loader for Pytorch"
      ]
    },
    {
      "metadata": {
        "id": "DpeZyrxZqXwQ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "train_loader = torch.utils.data.DataLoader(dataset=train_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle = True,\n",
        "                                          num_workers = 2)\n",
        "\n",
        "valid_loader = torch.utils.data.DataLoader(dataset=valid_data,\n",
        "                                          batch_size=batch_size,\n",
        "                                          shuffle = False,\n",
        "                                          num_workers = 2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "RI-KlWuBtKTv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Zp746Hwj1PBD",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# define train model"
      ]
    },
    {
      "metadata": {
        "id": "FsCt4zFkthxh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def train_model(model, loss_function, optimizer, data_loader):\n",
        "    model.train()\n",
        "    \n",
        "    current_loss = 0\n",
        "    current_acc = 0\n",
        "    \n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        \n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        with torch.set_grad_enabled(True):\n",
        "            \n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            \n",
        "            loss.backward()\n",
        "            \n",
        "            optimizer.step()\n",
        "            \n",
        "        current_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "        current_acc += torch.sum(predicted == labels.data)\n",
        "        \n",
        "    total_loss = current_loss / len(data_loader.dataset)\n",
        "    total_acc = 100 * (current_acc.double() / len(data_loader.dataset))\n",
        "    \n",
        "    print('Train Loss: {:.4f}, Accuracy: {:.4f}%'.format(total_loss, total_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WSL4fWYl_FPE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# define validation model"
      ]
    },
    {
      "metadata": {
        "id": "puwHwh0d4EN1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def val_model(model, loss_function, data_loader):\n",
        "    \n",
        "    model.eval()\n",
        "    \n",
        "    current_loss = 0\n",
        "    current_acc = 0\n",
        "    \n",
        "    for i, (inputs, labels) in enumerate(data_loader):\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        with torch.set_grad_enabled(False):\n",
        "            outputs = model(inputs)\n",
        "            \n",
        "            _, predicted = torch.max(outputs, 1)\n",
        "            \n",
        "            loss = loss_function(outputs, labels)\n",
        "            \n",
        "        current_loss += loss.item() * inputs.size(0)\n",
        "        \n",
        "        current_acc += torch.sum(predicted == labels.data)\n",
        "        \n",
        "    total_loss = current_loss / len(data_loader.dataset)\n",
        "    total_acc = 100 * (current_acc.double() / len(data_loader.dataset))\n",
        "    \n",
        "    print('Validation Loss: {:.4f}, Accuracy: {:.4f}%'.format(total_loss, total_acc))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bJZfO-702-I-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Train the Model"
      ]
    },
    {
      "metadata": {
        "id": "9R6sGQDw24wz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 170
        },
        "outputId": "7cb571ed-44f3-44bc-d6a9-b95f6651de86"
      },
      "cell_type": "code",
      "source": [
        "epoch = 3\n",
        "\n",
        "model = torchvision.models.resnet18(pretrained=True)\n",
        "\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "    \n",
        "num_features = model.fc.in_features\n",
        "\n",
        "model.fc = nn.Linear(num_features, 10)\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "loss_function = nn.CrossEntropyLoss()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.fc.parameters())\n",
        "\n",
        "for epch in range(epoch):\n",
        "    \n",
        "    print('Epoch {}/{}'.format(epch+1, epoch))\n",
        "    train_model(model, loss_function, optimizer, train_loader)\n",
        "    val_model(model, loss_function, valid_loader)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "Train Loss: 1.0464, Accuracy: 64.1760%\n",
            "Validation Loss: 0.7157, Accuracy: 75.6800%\n",
            "Epoch 2/3\n",
            "Train Loss: 0.8564, Accuracy: 69.9600%\n",
            "Validation Loss: 0.7112, Accuracy: 75.5800%\n",
            "Epoch 3/3\n",
            "Train Loss: 0.8378, Accuracy: 70.6960%\n",
            "Validation Loss: 0.6813, Accuracy: 76.7800%\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "5I_rHwCL-Kp1",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}